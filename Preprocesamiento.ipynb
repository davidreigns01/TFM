{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b11ee85",
   "metadata": {},
   "source": [
    "Este cuadernillo contiene todo el código empleado para realizar la parte de nuestro TFM relativa al preprocesamiento del dataset Youtube Video Trending Dataset. Incluye las siguientes secciones:\n",
    "\n",
    "- Instalación de subprogramas y librerías\n",
    "- Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d826b9",
   "metadata": {},
   "source": [
    "## Instalación de subprogramas y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53af425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import isodate #para manejar formato de duración ISO 8601\n",
    "import re #para manejar expresiones regulares\n",
    "from textblob import TextBlob\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pytesseract\n",
    "from datetime import datetime\n",
    "\n",
    "# Activar barra de progreso en pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3ed7b",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74bf39",
   "metadata": {},
   "source": [
    "### Lectura del archivo y filtro de vídeo único y suscriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9668d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\belga\\AppData\\Local\\Temp\\ipykernel_25100\\3992607573.py:8: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con 19866 vídeos únicos de canales pequeños (< 20.000 suscriptores)\n"
     ]
    }
   ],
   "source": [
    "# Ruta al archivo original grande\n",
    "ruta = \"youtube_trending_videos_global.csv\"\n",
    "\n",
    "# Leer por chunks para no saturar la memoria\n",
    "chunksize = 100_000\n",
    "filtrados = []\n",
    "\n",
    "for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
    "    # Filtrar canales con menos de 20.000 suscriptores\n",
    "    chunk_filtrado = chunk[chunk[\"channel_subscriber_count\"] < 20000]\n",
    "    filtrados.append(chunk_filtrado)\n",
    "\n",
    "# Unir todos los trozos filtrados\n",
    "df = pd.concat(filtrados, ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados por video_id, conservando el primero\n",
    "df = df.drop_duplicates(subset=\"video_id\", keep=\"first\")\n",
    "\n",
    "print(f\"Dataset cargado con {len(df)} vídeos únicos de canales pequeños (< 20.000 suscriptores)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7121ecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video_id', 'video_published_at', 'video_trending__date', 'video_trending_country', 'channel_id', 'video_title', 'video_description', 'video_default_thumbnail', 'video_category_id', 'video_tags', 'video_duration', 'video_dimension', 'video_definition', 'video_licensed_content', 'video_view_count', 'video_like_count', 'video_comment_count', 'channel_title', 'channel_description', 'channel_custom_url', 'channel_published_at', 'channel_country', 'channel_view_count', 'channel_subscriber_count', 'channel_have_hidden_subscribers', 'channel_video_count', 'channel_localized_title', 'channel_localized_description']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94d514",
   "metadata": {},
   "source": [
    "### Creación de columnas auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e287990",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9699d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_to_seconds(d):\n",
    "    try:\n",
    "        return isodate.parse_duration(d).total_seconds()\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    text = str(text)\n",
    "    if len(text) == 0:\n",
    "        return 0\n",
    "    upper = sum(1 for c in text if c.isupper())\n",
    "    return upper / len(text)\n",
    "\n",
    "def has_links(text):\n",
    "    return any(x in str(text).lower() for x in [\"http\", \"www\", \"bit.ly\", \"youtu.be\"])\n",
    "\n",
    "def convertir_a_hq(url):\n",
    "    if isinstance(url, str) and \"/default.jpg\" in url:\n",
    "        return url.replace(\"/default.jpg\", \"/hqdefault.jpg\")\n",
    "    return url\n",
    "\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        return img\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def preprocess_for_ocr(img_pil):\n",
    "    try:\n",
    "        img_gray = img_pil.convert(\"L\")\n",
    "        img_np = np.array(img_gray)\n",
    "        _, img_thresh = cv2.threshold(img_np, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return Image.fromarray(img_thresh)\n",
    "    except:\n",
    "        return img_pil\n",
    "\n",
    "def count_text(img_pil):\n",
    "    try:\n",
    "        img_preprocessed = preprocess_for_ocr(img_pil)\n",
    "        text = pytesseract.image_to_string(img_preprocessed)\n",
    "        return len(text.strip().split())\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def calculate_colorfulness(img_pil):\n",
    "    try:\n",
    "        img = np.array(img_pil)\n",
    "        (B, G, R) = cv2.split(img.astype(\"float\"))\n",
    "        rg = np.absolute(R - G)\n",
    "        yb = np.absolute(0.5 * (R + G) - B)\n",
    "        std_rg, std_yb = np.std(rg), np.std(yb)\n",
    "        mean_rg, mean_yb = np.mean(rg), np.mean(yb)\n",
    "        return np.sqrt(std_rg**2 + std_yb**2) + (0.3 * np.sqrt(mean_rg**2 + mean_yb**2))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def detectar_caras_en_url(url_imagen):\n",
    "    try:\n",
    "        resp = requests.get(url_imagen, stream=True, timeout=5)\n",
    "        if resp.status_code != 200:\n",
    "            return -1\n",
    "        imagen_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "        imagen = cv2.imdecode(imagen_array, cv2.IMREAD_COLOR)\n",
    "        if imagen is None:\n",
    "            return -1\n",
    "        gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        caras = face_cascade.detectMultiScale(gris, scaleFactor=1.1, minNeighbors=5)\n",
    "        return len(caras)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2fcf3",
   "metadata": {},
   "source": [
    "#### Creación de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8ad6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 1496534.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 737159.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 1257797.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 1316668.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 316604.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 689391.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 112876.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 545460.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 19866/19866 [00:00<00:00, 134949.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19866/19866 [2:31:49<00:00,  2.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19866/19866 [2:37:59<00:00,  2.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19866/19866 [2:32:29<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACIONES Y FEATURES DERIVADAS\n",
    "\n",
    "# Procesar URLs de miniatura\n",
    "if \"thumbnail_url_hq\" not in df.columns:\n",
    "    df[\"thumbnail_url_hq\"] = df[\"video_default_thumbnail\"].apply(convertir_a_hq)\n",
    "\n",
    "# Texto\n",
    "df[\"title_length\"] = df[\"video_title\"].astype(str).progress_apply(len)\n",
    "df[\"title_word_count\"] = df[\"video_title\"].astype(str).progress_apply(lambda x: len(x.split()))\n",
    "df[\"title_has_exclamation\"] = df[\"video_title\"].astype(str).progress_apply(lambda x: \"!\" in x)\n",
    "df[\"title_has_question\"] = df[\"video_title\"].astype(str).progress_apply(lambda x: \"?\" in x)\n",
    "df[\"title_uppercase_ratio\"] = df[\"video_title\"].astype(str).progress_apply(uppercase_ratio)\n",
    "df['title_sentiment'] = df['video_title'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "df[\"description_length\"] = df[\"video_description\"].astype(str).progress_apply(len)\n",
    "df['description_sentiment'] = df['video_description'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "df[\"has_external_links\"] = df[\"video_description\"].astype(str).progress_apply(has_links)\n",
    "df[\"tag_count\"] = df[\"video_tags\"].astype(str).progress_apply(lambda x: len(x.split(\",\")) if pd.notnull(x) else 0)\n",
    "\n",
    "# Tiempo\n",
    "df[\"published_at\"] = pd.to_datetime(df[\"video_published_at\"], errors=\"coerce\")\n",
    "df[\"hour_of_day\"] = df[\"published_at\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"published_at\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6])\n",
    "df[\"is_peak_hour\"] = df[\"hour_of_day\"].between(15, 17)\n",
    "\n",
    "# Duración\n",
    "df[\"video_duration_sec\"] = df[\"video_duration\"].progress_apply(duration_to_seconds)\n",
    "\n",
    "# Miniatura\n",
    "df[\"thumbnail_text_count\"] = df[\"thumbnail_url_hq\"].progress_apply(lambda x: count_text(download_image(x)))\n",
    "df[\"thumbnail_colorfulness\"] = df[\"thumbnail_url_hq\"].progress_apply(lambda x: calculate_colorfulness(download_image(x)))\n",
    "df[\"thumbnail_faces_count\"] = df[\"thumbnail_url_hq\"].progress_apply(detectar_caras_en_url)\n",
    "\n",
    "#Métricas\n",
    "df[\"views_per_second\"] = df[\"video_view_count\"] / (df[\"video_duration_sec\"] + 1)\n",
    "df[\"likes_per_view\"] = df[\"video_like_count\"] / (df[\"video_view_count\"] + 1)\n",
    "df[\"likes_per_sub\"] = df[\"video_like_count\"] / (df[\"channel_subscriber_count\"] + 1)\n",
    "df[\"views_per_sub\"] = df[\"video_view_count\"] / (df[\"channel_subscriber_count\"] + 1)\n",
    "df[\"viral_score\"] = df[\"views_per_sub\"] + df[\"likes_per_view\"] + df[\"likes_per_sub\"]\n",
    "df[\"is_viral\"] = (df[\"views_per_sub\"] > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17a1d4",
   "metadata": {},
   "source": [
    "#### Exportación dataset plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = \"videos_virales_final_plus.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Dataset guardado como '{output_csv}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e8ca4",
   "metadata": {},
   "source": [
    "#### Reordenación de columnas y exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abf52d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset guardado como 'videos_virales_final.csv'\n"
     ]
    }
   ],
   "source": [
    "ordered_cols = [\n",
    "\"video_id\", \"video_published_at\", \"channel_id\", \"video_title\", \"video_description\", \"video_default_thumbnail\",\n",
    "\"video_category_id\", \"video_tags\", \"video_duration\", \"video_definition\", \"video_view_count\", \"video_like_count\",\n",
    "\"video_comment_count\", \"channel_title\", \"channel_published_at\", \"channel_subscriber_count\", \"channel_video_count\",\n",
    "\"thumbnail_url_hq\", \"thumbnail_faces_count\", \"title_length\", \"title_word_count\", \"title_has_exclamation\",\n",
    "\"title_has_question\", \"title_has_keywords\", \"title_uppercase_ratio\", \"title_sentiment\", \"description_length\", \n",
    "\"description_sentiment\", \"has_external_links\", \"tag_count\", \"video_duration_sec\", \"published_at\", \"hour_of_day\", \n",
    "\"day_of_week\", \"is_weekend\", \"is_peak_hour\",\"thumbnail_text_count\", \"thumbnail_colorfulness\", \"is_viral\",\n",
    "\"viral_score\", \"views_per_second\", \"likes_per_view\", \"likes_per_sub\", \"views_per_sub\"\n",
    "]\n",
    "\n",
    "df = df[[col for col in ordered_cols if col in df.columns]]\n",
    "\n",
    "# Exportar\n",
    "output_csv = \"videos_virales_final.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Dataset guardado como '{output_csv}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
